{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "warming-mechanics",
   "metadata": {},
   "source": [
    "# Word Vectors\n",
    "Word vectors - also called *word embeddings* - are mathematical descriptions of individual words such that words that appear frequently together in the language will have similar values. In this way we can mathematically derive *context*. As mentioned above, the word vector for \"lion\" will be closer in value to \"cat\" than to \"dandelion\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-organization",
   "metadata": {},
   "source": [
    "## Vector values\n",
    "So what does a word vector look like? Since spaCy employs 300 dimensions, word vectors are stored as 300-item arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intense-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy and load the language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')  # make sure to use a larger model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acute-context",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.96635887e-01, -2.32740352e-03, -5.36607020e-02, -6.10564947e-02,\n",
       "       -4.08843048e-02,  1.45266443e-01, -1.08268000e-01, -6.27789786e-03,\n",
       "        1.48455709e-01,  1.90697408e+00, -2.57692993e-01, -1.95818534e-03,\n",
       "       -1.16141019e-02, -1.62858292e-01, -1.62938282e-01,  1.18210977e-02,\n",
       "        5.12646027e-02,  1.00078702e+00, -2.01447997e-02, -2.54611671e-01,\n",
       "       -1.28316596e-01, -1.97198763e-02, -2.89733019e-02, -1.94347113e-01,\n",
       "        1.26644447e-01, -8.69869068e-02, -2.20812604e-01, -1.58452198e-01,\n",
       "        9.86308008e-02, -1.79210991e-01, -1.55290633e-01,  1.95643142e-01,\n",
       "        2.66436003e-02, -1.64984968e-02,  1.18824698e-01, -1.17830629e-03,\n",
       "        4.99809943e-02, -4.23077159e-02, -3.86111848e-02, -7.47400150e-03,\n",
       "        1.23448208e-01,  9.60620027e-03, -3.32463719e-02, -1.77848607e-01,\n",
       "        1.19390726e-01,  1.87545009e-02, -1.84173390e-01,  6.91781715e-02,\n",
       "        1.28520593e-01,  1.48827005e-02, -1.78013414e-01,  1.10003807e-01,\n",
       "       -3.35464999e-02, -1.52476998e-02, -9.41195935e-02,  1.58633105e-02,\n",
       "       -1.29811959e-02,  1.40140295e-01, -1.47720069e-01, -3.81718054e-02,\n",
       "        4.66808230e-02,  3.31423879e-02,  7.97965974e-02,  1.60014004e-01,\n",
       "        8.90410226e-03, -1.01237908e-01,  7.39663988e-02,  2.47380026e-02,\n",
       "        4.26153988e-02,  9.66729969e-02,  2.87616011e-02,  7.22841993e-02,\n",
       "        1.76565602e-01,  7.55538046e-02,  1.10501610e-01, -1.02358103e-01,\n",
       "       -5.43345436e-02, -4.12176028e-02,  3.98623049e-02, -2.98339734e-03,\n",
       "       -5.32988012e-02,  1.90624595e-01, -6.42587021e-02, -1.76225007e-02,\n",
       "        3.94165330e-02, -1.14773512e-01,  4.25241649e-01,  2.07243040e-01,\n",
       "        2.60730416e-01,  1.31226778e-01, -8.00508037e-02,  6.88939020e-02,\n",
       "        7.05293044e-02, -1.10744104e-01,  4.14580032e-02,  5.13269613e-03,\n",
       "       -1.29179001e-01, -5.84542975e-02,  9.13560018e-02, -1.75975591e-01,\n",
       "        9.52741057e-02,  1.37699964e-02, -1.30865201e-01, -4.76420000e-02,\n",
       "        1.61670998e-01, -6.76959991e-01,  2.68619388e-01, -7.94106945e-02,\n",
       "        8.56394917e-02, -5.94138019e-02,  7.44821057e-02, -1.67490095e-01,\n",
       "        1.97447598e-01, -2.71580786e-01,  1.51915969e-02,  1.12019002e-01,\n",
       "       -4.32585999e-02, -1.03554968e-02,  6.33272156e-02,  5.20200143e-03,\n",
       "        4.94491048e-02, -1.07016601e-01, -6.45387918e-02, -1.76269561e-01,\n",
       "       -1.98135704e-01,  4.17800918e-02,  1.23686995e-02, -1.13280594e-01,\n",
       "       -4.03523073e-02, -4.21132054e-03, -9.65667963e-02, -7.12300017e-02,\n",
       "       -2.19088510e-01,  6.41715974e-02,  1.11634992e-01, -7.12868944e-02,\n",
       "       -8.27060193e-02,  1.53889004e-02,  6.84699565e-02, -5.50561920e-02,\n",
       "       -1.84788990e+00, -4.75010052e-02,  1.31487206e-01,  1.03359401e-01,\n",
       "        1.80857688e-01, -8.03041980e-02,  2.27739997e-02,  5.56868985e-02,\n",
       "        9.20986086e-02,  6.22248054e-02,  4.86670025e-02, -4.06427011e-02,\n",
       "        3.83703932e-02, -4.05869968e-02, -2.26339817e-01,  3.69174965e-02,\n",
       "       -1.30066186e-01,  1.27621710e-01,  2.76701003e-02, -1.39992401e-01,\n",
       "       -3.75526994e-02, -8.11104029e-02, -1.78196102e-01, -1.21652998e-01,\n",
       "       -5.88919744e-02, -1.06128812e-01, -4.72390745e-03, -1.14130601e-01,\n",
       "       -7.60087445e-02, -9.48704034e-02,  1.68780401e-01,  3.82669941e-02,\n",
       "       -1.68303996e-01, -1.30991384e-01, -2.46409744e-01,  1.42855030e-02,\n",
       "        1.23633012e-01,  7.95699935e-03, -3.22283022e-02,  3.75844017e-02,\n",
       "       -4.48104031e-02, -2.00578898e-01, -2.86081016e-01, -1.83181003e-01,\n",
       "       -5.46899159e-04,  6.52990937e-02,  2.34263036e-02, -7.60660022e-02,\n",
       "        1.13897599e-01, -7.05380812e-02,  1.30277812e-01,  2.83973999e-02,\n",
       "        1.73887815e-02, -1.71358977e-02,  1.78455990e-02,  1.86773703e-01,\n",
       "        1.83613986e-01, -4.05438878e-02,  1.28929759e-03, -3.71900201e-03,\n",
       "       -1.97373003e-01,  4.78463694e-02, -2.21408010e-01,  2.68826094e-02,\n",
       "        2.40951017e-01,  7.42616802e-02,  7.53984973e-02, -7.67349079e-02,\n",
       "       -5.37766796e-03, -8.06540065e-03,  1.88790001e-02,  8.31135064e-02,\n",
       "       -5.20760007e-02,  1.29393607e-01,  4.09864075e-02,  7.31946975e-02,\n",
       "       -1.64099425e-01,  1.17529690e-01, -6.96440935e-02,  1.91028208e-01,\n",
       "        1.01721905e-01,  6.34808987e-02, -8.29815865e-02, -6.95784390e-03,\n",
       "       -1.69757873e-01, -2.02478573e-01,  3.65395918e-02,  1.32345587e-01,\n",
       "        3.53013016e-02,  2.27603033e-01, -1.52753398e-01,  7.80210178e-03,\n",
       "        2.06879750e-02, -8.63540452e-03,  9.85722095e-02, -2.91380938e-02,\n",
       "       -1.42988954e-02, -9.39018354e-02,  1.43968105e-01,  7.82396942e-02,\n",
       "       -1.93540990e-01, -9.36544985e-02, -8.23533013e-02,  4.40272018e-02,\n",
       "       -2.22195080e-03, -1.29856914e-01, -1.53841600e-01, -1.55329984e-02,\n",
       "       -2.55266696e-01,  1.14425398e-01, -1.03161987e-02, -4.66439016e-02,\n",
       "       -5.69390282e-02,  7.72780031e-02,  1.28908500e-01,  1.61679000e-01,\n",
       "        1.50837511e-01,  6.18334934e-02, -9.06937942e-02, -3.52137014e-02,\n",
       "        1.35956988e-01,  7.52059072e-02,  5.73905036e-02, -1.65402606e-01,\n",
       "        1.68419987e-01, -1.83722824e-01,  5.91069926e-03, -1.25354990e-01,\n",
       "        3.95771042e-02,  5.67352995e-02, -5.63519308e-03,  1.53597593e-01,\n",
       "       -6.84822723e-02, -1.40976995e-01, -3.62732522e-02, -2.61475928e-02,\n",
       "        2.50091963e-02,  1.18994810e-01, -2.66857035e-02,  7.50442073e-02,\n",
       "        2.04583794e-01,  4.37736101e-02, -8.17096978e-02,  6.80228025e-02,\n",
       "        5.50465994e-02, -2.39979066e-02,  7.68290013e-02, -5.76773956e-02,\n",
       "        8.30340981e-02,  3.63199934e-02, -1.65820405e-01,  2.55408939e-02,\n",
       "       -5.30679002e-02, -1.35961995e-01, -1.03501797e-01,  1.36406809e-01,\n",
       "        9.66293067e-02,  7.33902007e-02, -1.83055893e-01, -2.73141060e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'The quick brown fox jumped over the lazy dogs.')\n",
    "\n",
    "doc.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stylish-pickup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-climb",
   "metadata": {},
   "source": [
    "## Identifying similar vectors\n",
    "The best way to expose vector relationships is through the `.similarity()` method of Doc tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exact-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car car 1.0\n",
      "car bike 0.5357731\n",
      "car bus 0.48169607\n",
      "bike car 0.5357731\n",
      "bike bike 1.0\n",
      "bike bus 0.39376006\n",
      "bus car 0.48169607\n",
      "bus bike 0.39376006\n",
      "bus bus 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a three-token Doc object:\n",
    "tokens = nlp(u'car bike bus')\n",
    "\n",
    "# Iterate through token combinations:\n",
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text, token2.text, token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-tennis",
   "metadata": {},
   "source": [
    "## Vector norms\n",
    "It's sometimes helpful to aggregate 300 dimensions into a [Euclidian (L2) norm](https://en.wikipedia.org/wiki/Norm_%28mathematics%29#Euclidean_norm), computed as the square root of the sum-of-squared-vectors. This is accessible as the `.vector_norm` token attribute. Other helpful attributes include `.has_vector` and `.is_oov` or *out of vocabulary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collected-syntax",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car True 7.149045 False\n",
      "bike True 7.237066 False\n",
      "bus True 7.0950456 False\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp(u'car bike bus')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-copyright",
   "metadata": {},
   "source": [
    "## Vector arithmetic\n",
    "Believe it or not, we can actually calculate new vectors by adding & subtracting related vectors. A famous example suggests\n",
    "<pre>\"king\" - \"man\" + \"woman\" = \"queen\"</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "metropolitan-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'woman', 'she', 'who', 'fox', 'brown', 'when', 'dare', 'was', 'not']\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    "\n",
    "king = nlp.vocab['king'].vector\n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector\n",
    "\n",
    "# Now we find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
    "new_vector = king - man + woman\n",
    "computed_similarities = []\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    # Ignore words without vectors and mixed-case words:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity = cosine_similarity(new_vector, word.vector)\n",
    "                computed_similarities.append((word, similarity))\n",
    "\n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "\n",
    "print([w[0].text for w in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-toner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
